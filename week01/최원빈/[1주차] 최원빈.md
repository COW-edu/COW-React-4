# week 1

버전 0930 12pm

# 브라우저 구조

<img width="415" alt="스크린샷 2024-09-30 오전 11 27 00" src="https://github.com/user-attachments/assets/bf3562cf-d472-417c-91b7-050cbbc29ff7">

# 사용자 인터페이스

<img width="418" alt="스크린샷 2024-09-30 오전 11 27 08" src="https://github.com/user-attachments/assets/32a5dfc8-a784-4f23-bb2c-2a4190dface2">

말그대로 사용자가 사용하는 인터페이스

# 렌더링 엔진

말 그대로 render(그리다)

웹사이트를 그리는 곳.

• **HTML과 CSS를 파싱**해 최종적으로 화면에 그려주며, HTML 및 XML 문서와 이미지를 표시할 수 있다. (플러그인이나 브라우저 확장 기능을 이용하면 PDF와 같은 다른 유형도 표시할 수 있다.)

# 브라우저 엔진?

사용자가 뒤로 가기를 눌렀다치면, 렌더링엔진한테 뒤로가! 라고 씨부려야하느데 그게 브라우저 엔진의 역할

# 자바스크립트 해석기

브라우저는 자바스크립트를 해석할수있다. 자바스크립트 해석기로 인해서 인식이 가능함

크롬은 V8엔진을 이용함 !

# 실질적으로인 단계를 설명해봄

## 원빈이가 네이버에 들어가고싶어서 주소 땅 치고 엔터누름

먼저 네이버.com을 엔터를 누르면 브라우저는 이해할수없다. 컴퓨터는 IP주소를 찾아야함

# 1. 컴퓨터는 IP주소를 찾는다. (TO DNS)

### DNS (Domain Name System)

인터넷에서 도메인 이름을 IP주소로 변환하는 시스템임. 사용자가 웹사이테 접속할때, 도메인 이름(예: [www.example.com](http://www.example.com/))을 입력하면 DNS가 그 도메인 이름에 대응하는 IP 주소(예: 192.0.2.1)를 찾아서 연결해줌.

더 쉽게 설명하면

내가 [www.naver.com](http://www.naver.com) → 192.0.2,.1의 형태로 바꿔주는 시스템

DNS == 전화번호부 라 생각하면 쉽다

## 2. 리소스를 요청한다.

주소를 가지고 들어감 서버에 그리고 요청함

근데 준게 101010101010 바이트 스트림으로 되어있어서 뭐라는지 모름 ㅠㅠ

그럼 우리 브라우저는 인코딩을 해야한다 (우리가 이해할수있는 HTML)로 인코딩을 실시한다. 그 잘 우리가아는 UTF-8 한국어 ㅎㅎ.

<img width="437" alt="스크린샷 2024-09-30 오전 11 27 15" src="https://github.com/user-attachments/assets/33f406fa-cd5e-490c-ae41-a55cd7467884">

## 3. 토큰화

이름 어렵다. 근데 걍 우리가 가지고 온 인코딩된 html값을 한글자 한글자 읽는 것. 다시 또 문자 하나하나 읽고 의미를 해석함

<img width="390" alt="스크린샷 2024-09-30 오전 11 27 23" src="https://github.com/user-attachments/assets/b819bc2a-2553-4cc4-8a08-d3020bc95cf6">

## 4. 노드

위에서 토큰은 대충 읽는 다느것을 이해했다. 노드는 이제 그 읽은 것들중 의미있는것을 해석하여 분류해놓는다.

## 5. DOM TREE

노드에다가 관계를 주입한것

이들을 모델화한것이 DOMTREE.

계층이 뚜렷한 html DOM TREE를 만든다.

# 요약

- 브라우저 구조: 사용자 인터페이스, 렌더링 엔진, 브라우저 엔진, 자바스크립트 해석기 등으로 구성
- 웹 페이지 로딩 과정: DNS 조회, 리소스 요청, 인코딩, 토큰화, 노드 생성, DOM 트리 및 CSSOM 트리 구축
- 렌더링 엔진: HTML과 CSS를 파싱하여 화면에 표시
- 자바스크립트 해석기: 브라우저의 자바스크립트 실행 담당 (예: 크롬의 V8 엔진)
- DNS: 도메인 이름을 IP 주소로 변환하는 시스템
- DOM 트리: HTML 문서의 구조를 나타내는 계층적 트리 구조

# DOM

DOCUMENT → HTML

크롬 이 공장이라고 비유하면

HTML은 주문서임 (주문서 안에는 구체적인 녀석들이 있겠다)

공장은 그 주문서를 보고 뚝딱뚝딱 제작을 한다.

ex input태그는 지정된 타입에 따라 색다른 기능들을 하여 value라는 속성에 나가게 설계되는 것잉다

그것들을 모으고 모아 만드는 .. 즉, HTML이란 코드로 설계된 웹페이지가 브라우저 안에서 화면에 나타나고 이벤트에 반응하고 등등 기능들을 수행할 객체들로 실체화된 형태임

즉 html 요소 각각 하나가 부품이라 치고, 이 부품들을 모아서 조립된 웹페이지 하나가 DOM. 이 DOM은 이제 자바스크립트로 조작된다.

## DOM 은 브라우저라는 공장에서 찍어낸 놈이다.

그럼 파이어폭스, 크롬, 엣지에서 만든 녀석들의 결과물도 비슷하겠다.

그래서 우리가 웹사이트를 어디서 접속하듯 비슷하다.

## NODE?

DOM의 모든 요소들 (부품들)은 노드라는 녀석으로 부터 “상속” 받는다.

모든 HTML 요소 들은 노드다. 라고 이해해보자

강아지, 토끼 포유류..

포유류가 척추가 있으면 ( 강아지 토끼도 척추가 있다)

# DOM 좀 더 부연 설명..

쉽게말해, DOM의 모습은 트리 형태로서 자바스크립트로 하여금

1. 새로운 HTML 요소나 속성을 추가
2. 존재하는 HTML 요소나 속성을 제거
3. HTML 문서의 모든 HTML 요소를 변경
4. HTML 문서의 모든 HTML 속성을 변경할
5. 문서의 모든 CSS 스타일을 변경
6. HTML 문서에 새로운 HTML 이벤트를 추가
7. HTML 문서의 모든 HTML 이벤트에 반응
   할 수 있게 해줘 웹 페이지를 동적으로 만드는데 알아야할 중요한 개념이다.
   위 일련의 행위를 하는 것을 DOM에 접근한다 라고 흔히들 말한다.

리액트 같은 라이브러리나 비슷한 기능을 제공하는 프레임워크들 (Vue / Angular)이 나오기 전에
DOM에 접근을 하려면 DOM API들인 method와 property들을 자바스크립트로 사용해서 접근해서 1~7번의 행위를 해야했는데 html 파일과 자바스크립트 파일이 분리되어 있었기 때문이다.

하지만 리액트의 등장으로 컴포넌트 (view에서 최소한의 UI 단위로 나눠진 블록) 단위로 html과 자바스크립트를 작성할 수 있게 되어 별로의 다른 파일이 존재할 필요가 없어진 것이다.
또한 JSX문법은 자바스크립트와 html을 함께 사용할 수 있게 해주어 DOM에 접근하기 위해 method와 property로 접근할 필요없이 직접 코딩을 하면 된다.
마지막으로 리액트가 제공하는 가상본, 즉 가상 DOM은 실제 DOM에 접근하기 전에 바뀐 부분만 체크하여 그 부분의 실제 DOM 요소에 접근하여 조작하게 해주어 성능면에서도 장점을 보인다.

정리하자면 DOM은 책 한권을 한장 한장 분리 시켜서 같은 대단원별로, 그 안에서 소단원 별로 so on.. 트리 구조로 바닥에 펼쳐놓는 것이다.
JSX문법 이전에는 그 한장 한장을 실제로 찾아서 (tree 구조 이기에 root, 최상단부터 찾아 들어가게 된다) 수정사항을 수정해야 했다면 리액트는 그 한장 한장을 각 파일로 컴퓨터에 저장할 수 있게 해줘 작성과 수정에 편리함을 준 것이다.

# Virtual DOM?

## SINGLE PAGE APP 만드려고요

부드럽고 깔꼼한 부드러운 HTML.. ㅎㅎ

쌩 자바스크립트로도 가능함 근데 너무 길어짐

# 그전에.. 브라우저 렌더링 과정

- Dom tree 생성 (랜더 엔진이 html 파싱하여 DOM 노드로 이뤄진 트리 생성)
- render tree 생성 (css 파일 파싱)
- DOM + CSSOM == RENDER TREE
- Layout (스크렌에서의 위치결정) (reflow)
- Paint( 그리기)

이 과정을 반복

이렇게 말하면 졸라어려움

만약 인스타그램에서 내가 좋아요를 누르거나 댓글을달면

전체 노드들이 처음부터 다시 그려지는 것임

이 조작이 쬐까 비효율적..

## SPA (Single Page APP)

이 유행되서 브라우저 단에서 자바스크립트가 관리하는 효율적인 시스템이 일어나며

최적화가 필요해진 신시대가 열림

# Virtual DOM은 원래의 DOM의 도모다치

좀더 여려운 말로 HTML DOM의 추상화

실제 DOM이 가지고 있는 API는 없지만 속성은 갖고 있음

1. 데이터가 변경되면 UI는 virtual DOM에 렌더링
2. 이전 virtualDOM의 내용과 변경사항 파악
3. 바뀐부분만 실제 DOM에 적용

원본 DOM에는 필요한 변화만 적용 소시테, 전체의 DOM을 다 바꿀필요없음

## 어케쓰나요?

html 기반 Js 코드로 활용됨

실제 DOM이 아닌 메모리에서 활용

또한 연산비용도 적음 (요소가 30개 바뀌어도 다 묶어서 한번 실행)

개꿀이네요
<img width="413" alt="스크린샷 2024-09-30 오전 11 27 39" src="https://github.com/user-attachments/assets/63f716dc-26ea-4cf7-9735-440f9792d6d2">

리액트가 대표적인 VirtualDOM을 쓰는 놈임

### JSX?

html태그 처럼 생겼지만 자바스크립트의 확장 문법이라 생각하면 쉬움

### 이런식으로 실제 DOM으로 render함

<img width="369" alt="스크린샷 2024-09-30 오전 11 27 48" src="https://github.com/user-attachments/assets/98cb020e-e571-49af-b1c1-c61baca92566">

<img width="420" alt="스크린샷 2024-09-30 오전 11 28 00" src="https://github.com/user-attachments/assets/f3549067-20d6-41c6-853a-f90bb497cd1d">

# DIFFING 알고리즘 ( 구별하다)

위에서 했던 기능을 알고리즘화 한것 (리액트가)

virtual DOM이 업데이트되면, React는 무엇이 바뀌었는지 업데이트 이전과 이후에 스냅샷을 비교하여 어떤것이 바뀌었는가 검사하는 거임

좀더 설명하면 이건데…

<img width="364" alt="스크린샷 2024-09-30 오전 11 28 09" src="https://github.com/user-attachments/assets/1c71953c-4a76-4e0f-b28f-9178ee1d743a">

쩄든 비교해서 뭐가 바뀌었나를 파악하는것!!!!

# 실제 예시 ㅇㅇ

<img width="420" alt="스크린샷 2024-09-30 오전 11 28 20" src="https://github.com/user-attachments/assets/4d855add-99a4-4fdc-b526-614e8db390d0">

클릭하면 이미지가 늘어나는 앱이라 생각

2.

<img width="422" alt="스크린샷 2024-09-30 오전 11 28 32" src="https://github.com/user-attachments/assets/f1392280-0571-449f-85dc-cea080d5c7c1">

이미지가 추가가 되었으니 자바스크립트 코드의 변경이 일어남

그럼 이전 시점과 비교를 함

<img width="426" alt="스크린샷 2024-09-30 오전 11 28 41" src="https://github.com/user-attachments/assets/39a8f0c5-f57b-4284-b97f-a455700a11e2">

바꾸면 ..

귀여운 그림이 하나 추가되겠다 ㅇㅋ

# 그럼 대깨 virtual DOM이 좋겠네요?

그건 아님

인터렉션이 발생하지 않는 ( 단순 정보 일방향) 사이트일경우

그럴필요는없대용

또한 diffing 알고리즘또한 조상님이 대신 해주는것이 아니기때문에

고려해야함

spa로 제작된 큰 규모는 근데 웬만하면.. virtual DOM이 좋겠네요 ㅋ

# SPA

를 알기전에 MPA먼저 알아보자 ㅋ

도 알기전에 일단 APP에 대해 알아봐야함

# Application

사용자가 특정 작업을 수행할 수 있도록 설계된 소프트웨어 프로그램

헷갈린다면 운영체제의 자원을 써서 동작하는 놈

그래도 헷갈린다면 롤, 워드, 등등등 이 앱임

• **애플리케이션**은 사용자가 특정 작업을 수행하는 데 중점을 둔 소프트웨어입니다.

• **프로그램**은 좀 더 포괄적인 용어로, 애플리케이션도 프로그램의 일종입니다. 프로그램은 특정 작업을 수행하는 일련의 명령어를 뜻합니다.

• **시스템 소프트웨어**는 운영체제나 드라이버처럼 하드웨어와 소프트웨어의 상호작용을 관리하는 소프트웨어입니다. 시스템 소프트웨어는 애플리케이션이 하드웨어 자원을 효율적으로 사용할 수 있도록 지원합니다.

# MPA (Multi-page-Application)

두개 이상의 페이지로 구성된 애플리케이션

클릭이나 이벤트 ( 인터렉션이 ) 발생할때마다 해당 앱이 새로고침되는 전통적인 방식

랜더링의 방식

## Mpa use SERVER SIDE RENDERING

SSR라고도 불리죠

서버로부터 완전하게 만들어진 HTML파일로 전체로 렌더링
<img width="417" alt="스크린샷 2024-09-30 오전 11 28 50" src="https://github.com/user-attachments/assets/c59caf0f-a8d3-44c2-a0ee-085a373ffd38">

1. 나무를 옮겨보자

<img width="418" alt="스크린샷 2024-09-30 오전 11 28 58" src="https://github.com/user-attachments/assets/b6707fb8-fbb7-48bf-be0f-6f509e321a7f">

<img width="418" alt="스크린샷 2024-09-30 오전 11 29 07" src="https://github.com/user-attachments/assets/1cbc58a9-2e78-476c-9d71-b8b3213dae24">

응답할때는 html 파일로 줌 (서버가)

<img width="420" alt="스크린샷 2024-09-30 오전 11 29 37" src="https://github.com/user-attachments/assets/cc92609b-513a-46bb-ac38-14cf4d7e1e15">

받은걸 모조리 서버부터 다시 다운 ㅠㅠ

<img width="393" alt="스크린샷 2024-09-30 오전 11 29 46" src="https://github.com/user-attachments/assets/c35fa9bc-ae45-4e59-b734-995af48d3109">

그래서 화면이 깜빡이고 앱이 재시작된다.

# 개구린거아닌가요?

### 장점

검색 엔진 최적화에 유리

검색엔진이 웹을 크롤링하면서 페이지에 컨텐츠 색인을 생성하는 과정

화면 구성 웹페이지가 각각 있어서 이점에서 유리

- 빠른 초기 로딩 속도

### 단점

사용자 경험 구림 + 서버 부하

### 크롤링?

**크롤링의 동작 방식**

1. **시작점 설정 (Seed URL)**: 크롤러는 웹사이트의 특정 URL(예: 홈 페이지)에서 시작합니다.

2. **페이지 다운로드**: 크롤러는 해당 페이지의 HTML 문서를 다운로드하고, 페이지에 포함된 텍스트, 이미지, 링크 등의 데이터를 수집합니다.

3. **링크 추출 및 탐색**: 크롤러는 웹 페이지 안의 링크들을 분석하여 새로운 페이지를 찾습니다. 이렇게 찾은 링크들은 큐에 추가되고, 크롤러는 이들을 순차적으로 방문하여 데이터를 계속 수집합니다.

4. **데이터 저장**: 수집된 데이터는 로컬 파일이나 데이터베이스에 저장되며, 이후 분석하거나 처리할 수 있습니다.

**크롤링의 용도**

1. **검색 엔진**: 구글이나 네이버 같은 검색 엔진은 웹 크롤러를 사용하여 수많은 웹 페이지를 탐색하고 인덱스를 생성하여, 사용자가 검색할 때 적절한 페이지를 빠르게 찾을 수 있게 합니다.

2. **데이터 수집 및 분석**: 특정 웹사이트에서 상품 정보, 리뷰, 기사 등을 대량으로 수집하여 분석하는 데 사용됩니다.

3. **가격 비교 사이트**: 여러 쇼핑몰의 가격을 비교하는 사이트는 크롤링을 통해 실시간으로 상품 정보를 수집합니다.

4. **뉴스 수집**: 뉴스 웹사이트에서 새로운 기사를 자동으로 수집하여 보여주는 뉴스 집계 사이트들도 크롤링을 이용합니다.

**크롤링의 장단점**

**장점:**

• **자동화**: 크롤러는 수많은 웹 페이지를 사람이 일일이 탐색하지 않아도 자동으로 수집할 수 있습니다.

• **빠른 데이터 수집**: 대량의 데이터를 빠르게 수집할 수 있어 시간과 노력을 절약합니다.

**단점:**

• **차단 가능성**: 웹사이트에 따라 크롤링을 막기 위해 robots.txt 파일을 통해 크롤러의 접근을 제한하거나, 너무 많은 요청을 보내는 경우 서버에서 차단할 수 있습니다.

• **법적 문제**: 저작권이나 사이트의 이용약관을 위반할 수 있기 때문에, 데이터를 수집할 때는 주의가 필요합니다.

# SPA (single page app)

얘는 렌더링 방식으로 클라이언트 사이드 렌더링

CSR이라고도 하죠 를 채택함

# CSR (Client Side Rendering)

똑같이 서버에 req를함

또 서버는 response를 함

차이점은 모든 js파일까지 다 받아야해서 초기 로딩속도가 느림

위의 예시에서 나무를 바꾸려고 서버에 요구를 했잖아

그때 csr은 그냥 나무라는 요소의 데이터만 가져다줌

따라서 깜빡이진 않음

# 장점

- 졸라 빠르며 서버 부하가 없음
- 사용자입장에선 친화적임
- 부드러운 이동

# 단점

- 검색엔진 최적화에 불리..
- 크롤러가 오작동
- 초기 로딩속도가 김

# 질문

## 그럼 SPA는 죽어다 깨어나도 ssr못하고 csr만 하나요?

ㄴㄴ 그건아님

모든것이 다 이분법적으로 나눠지는 시스템이 아님

# 그럼 뭐 어쩌라는건가요

컨텐츠를 보고 해야합니다 (개발을)

모든 부분을 csr 혹은 ssr로 개발을 하는 건 멍청이

만약 정보제공만을 위한 단방향성 개발이 필요하면

ssr (server side rendering)

즉 서버와 접촉이 많이 없는 컨텐츠이면 이게 맞고

만약 동적인 움직임이 많거나 사용자와의 접촉이 많아 서버와의 접촉이 많아지면

csr (client side Rendering)으로 하는게 맞겠네요.

정치마냥 갈라치기 ㄴㄴ
