# week 1

피드백 이후 변경사항 최신화했습니다! 10.02 17:09

# 브라우저 구조

<img width="415" alt="스크린샷 2024-09-30 오전 11 27 00" src="https://github.com/user-attachments/assets/bf3562cf-d472-417c-91b7-050cbbc29ff7">

# 사용자 인터페이스

<img width="418" alt="스크린샷 2024-09-30 오전 11 27 08" src="https://github.com/user-attachments/assets/32a5dfc8-a784-4f23-bb2c-2a4190dface2">

말그대로 사용자가 사용하는 인터페이스

# 렌더링 엔진

말 그대로 render(그리다)

웹사이트를 그리는 곳.

• **HTML과 CSS를 파싱**해 최종적으로 화면에 그려주며, HTML 및 XML 문서와 이미지를 표시할 수 있다. (플러그인이나 브라우저 확장 기능을 이용하면 PDF와 같은 다른 유형도 표시할 수 있다.)

# 브라우저 엔진

사용자가 뒤로 가기를 눌렀다치면, 렌더링엔진한테 뒤로가! 그게 브라우저 엔진의 역할

# 자바스크립트 해석기

브라우저는 자바스크립트를 해석할수있다. 자바스크립트 해석기로 인해서 인식이 가능함

크롬은 V8엔진을 이용함 !

# 실질적으로인 단계

## 네이버에 들어가고싶어서 주소 땅 치고 엔터누름

먼저 네이버.com을 엔터를 누르면 브라우저는 이해할수없다. 컴퓨터는 IP주소를 찾아야함

# 1. 컴퓨터는 IP주소를 찾는다. (TO DNS)

### DNS (Domain Name System)

인터넷에서 도메인 이름을 IP주소로 변환하는 시스템임. 사용자가 웹사이테 접속할때, 도메인 이름(예: [www.example.com](http://www.example.com/))을 입력하면 DNS가 그 도메인 이름에 대응하는 IP 주소(예: 192.0.2.1)를 찾아서 연결해줌.

더 쉽게 설명하면

내가 [www.naver.com](http://www.naver.com) → 192.0.2,.1의 형태로 바꿔주는 시스템

DNS == 전화번호부 라 생각하면 쉽다

## 2. 리소스를 요청한다.

주소를 가지고 들어감 서버에 그리고 요청함

근데 준게 101010101010 바이트 스트림으로 되어있어서 뭐라는지 모름 ㅠㅠ

그럼 우리 브라우저는 인코딩을 해야한다 (우리가 이해할수있는 HTML)로 인코딩을 실시한다. 그 잘 우리가아는 UTF-8

<img width="437" alt="스크린샷 2024-09-30 오전 11 27 15" src="https://github.com/user-attachments/assets/33f406fa-cd5e-490c-ae41-a55cd7467884">

## 3. 토큰화

우리가 가지고 온 인코딩된 html값을 한글자 한글자 읽는 것. 다시 또 문자 하나하나 읽고 의미를 해석함

<img width="390" alt="스크린샷 2024-09-30 오전 11 27 23" src="https://github.com/user-attachments/assets/b819bc2a-2553-4cc4-8a08-d3020bc95cf6">

## 4. 노드

위에서 토큰은 대충 읽는 다느것을 이해했다. 노드는 이제 그 읽은 것들중 의미있는것을 해석하여 분류해놓는다.

## 5. DOM TREE

노드에다가 관계를 주입한것

이들을 모델화한것이 DOMTREE.

계층이 뚜렷한 html DOM TREE를 만든다.

# 과정을 요약하자면.

- 브라우저 구조: 사용자 인터페이스, 렌더링 엔진, 브라우저 엔진, 자바스크립트 해석기 등으로 구성
- 웹 페이지 로딩 과정: DNS 조회, 리소스 요청, 인코딩, 토큰화, 노드 생성, DOM 트리 및 CSSOM 트리 구축
- 렌더링 엔진: HTML과 CSS를 파싱하여 화면에 표시
- 자바스크립트 해석기: 브라우저의 자바스크립트 실행 담당 (예: 크롬의 V8 엔진)
- DNS: 도메인 이름을 IP 주소로 변환하는 시스템
- DOM 트리: HTML 문서의 구조를 나타내는 계층적 트리 구조

# DOM

DOM → HTML? 이렇게 결론 내리면 안됀다.

크롬 (브라우저)를 공장이라고 비유하면

HTML은 주문서임 (주문서 안에는 구체적인 녀석들이 있겠다)

공장은 그 주문서를 보고 뚝딱뚝딱 제작을 한다.

ex input태그는 지정된 타입에 따라 색다른 기능들을 하여 value라는 속성에 나가게 설계되는 것.

그것들을 모으고 모아 만드는 .. 즉, HTML이란 코드로 설계된 웹페이지가 브라우저 안에서 화면에 나타나고 이벤트에 반응하고 등등 기능들을 수행할 객체들로 실체화된 형태임

즉 html 요소 각각 하나가 부품이라 치고, 이 부품들을 모아서 조립된 웹페이지 하나가 DOM. 또한 이 DOM은 이제 자바스크립트로 조작이 가능\

그렇게 만들어진 DOM은 필연적으로 tree 구조이니.
DOM TREE라고도 불리는 것.

## DOM 은 브라우저라는 공장에서 찍어낸 것이다?

그럼 파이어폭스, 크롬, 엣지에서 만든 녀석들의 결과물도 비슷하겠다. ( 다른 공장이라도 결과물은 비슷할테니까)

그래서 우리가 웹사이트를 어디서 접속하듯 비슷하다. ( 크롬으로 접속하든, 파이어 폭스로 접속하든 네이버에 들어가면 비슷하다.)

## NODE?

노드는 DOM 트리의 구성요소의 기본 단위
즉, 쉽게말하면 여러 태그들은 모두 노드입니다. DOM의 모든 요소들 (부품들)은 노드라는 녀석으로 부터 “상속” 받는다.

모든 HTML 요소 들은 노드다. 라고 이해하면 쉽다.

공통된 특성의 역할 상속 받는 메서드의 기능

이 공통된 특성들은 DOM 트리에서 모든 노드가 공통적으로 사용할 수 있는 기능을 제공합니다. 예를 들어, div span 요소 모두 이 Node 클래스의 속성과 메서드를 통해 자신의 자식 요소나 부모 요소를 다룰 수 있고, 자신을 복제하거나 이동시킬 수도 있습니다.

## 리액트의 등장

리액트 같은 라이브러리나 비슷한 기능을 제공하는 프레임워크들 (Vue / Angular)이 나오기 전에
DOM에 접근을 하려면 DOM API들인 method와 property들을 자바스크립트로 사용해서 접근해서 1~7번의 행위를 해야했는데 html 파일과 자바스크립트 파일이 분리되어 있었기 때문이다.

하지만 리액트의 등장으로 컴포넌트 (view에서 최소한의 UI 단위로 나눠진 블록) 단위로 html과 자바스크립트를 작성할 수 있게 되어 별로의 다른 파일이 존재할 필요가 없어진 것이다.

## 리액트의 장점과 JSX

또한 JSX문법은 자바스크립트와 html을 함께 사용할 수 있게 해주어 DOM에 접근하기 위해 method와 property로 접근할 필요없이 직접 코딩을 하면 된다.

마지막으로 리액트가 제공하는 가상본, 즉 가상 DOM은 실제 DOM에 접근하기 전에 바뀐 부분만 체크하여 그 부분의 실제 DOM 요소에 접근하여 조작하게 해주어 성능면에서도 장점을 보인다.

정리하자면 DOM은 책 한권을 한장 한장 분리 시켜서 같은 대단원별로, 그 안에서 소단원 별로 트리 구조로 바닥에 펼쳐놓는 것이다.

JSX문법 이전에는 그 한장 한장을 실제로 찾아서 (tree 구조 이기에 root, 최상단부터 찾아 들어가게 된다) 수정사항을 수정해야 했다면 리액트는 그 한장 한장을 각 파일로 컴퓨터에 저장할 수 있게 해줘 작성과 수정에 편리함을 준 것이다.

# Virtual DOM?

DOM과는 달리 메모리 상에 존재하는 가벼운 복사본.

이 방식은 성능 최적화를 목적으로 도입되었으며, 실제로 웹 페이지를 빠르게 업데이트하는 데 큰 도움.

## 왜 탄생했는가?

, DOM은 HTML 문서를 트리 구조로 표현한 것입니다. 브라우저는 이 트리를 바탕으로 웹 페이지를 렌더링합니다. 그런데 DOM을 자주 업데이트하면(즉, 브라우저가 트리를 다시 그려야 할 때마다), 많은 성능 부담이 생깁니다. 특히, 큰 웹사이트나 자주 변화하는 UI에서는 이 부담이 커집니다.

이런 이유 브라우저가 트리를 재구성하니 부담이 커질수밖에 없다.
(아래에 렌더링과정을)

# 그전에.. 브라우저 렌더링 과정

- Dom tree 생성 (랜더 엔진이 html 파싱하여 DOM 노드로 이뤄진 트리 생성)
- render tree 생성 (css 파일 파싱)
- DOM + CSSOM == RENDER TREE
- Layout (스크렌에서의 위치결정) (reflow)
- Paint( 그리기)

이 과정을 반복

# 실예시로 들어본다면.

만약 인스타그램에서 내가 좋아요를 누르거나 댓글을달면

전체 노드들이 처음부터 다시 그려지는 것임
이 과정은 비효율적이라고 볼 수있다.

## SPA (Single Page APP)

이 유행되서 브라우저 단에서 자바스크립트가 관리하는 효율적인 시스템이 일어나며

최적화가 필요해진 신시대가 열림 (최근)

# Virtual DOM은 원래의 DOM의 친구이다.

좀더 여려운 말로 HTML DOM의 추상화

실제 DOM이 가지고 있는 API는 없지만 속성은 갖고 있음

1. 데이터가 변경되면 UI는 virtual DOM에 렌더링
2. 이전 virtualDOM의 내용과 변경사항 파악
3. 바뀐부분만 실제 DOM에 적용

원본 DOM에는 필요한 변화만 적용 따라서 전체의 DOM을 다 바꿀필요없음

## 활용 장소와 방법

html 기반 Js 코드로 활용됨

실제 DOM이 아닌 메모리에서 활용

또한 연산비용도 적음 (요소가 30개 바뀌어도 다 묶어서 한번 실행)

<img width="413" alt="스크린샷 2024-09-30 오전 11 27 39" src="https://github.com/user-attachments/assets/63f716dc-26ea-4cf7-9735-440f9792d6d2">

리액트가 대표적인 VirtualDOM을 쓰는 라이브러리.

## 예시 코드

### 그냥 DOM 조작

// 일반 DOM 조작 예시
const element = document.getElementById('myElement');
element.innerHTML = 'Hello, world!'; // DOM에 직접 변경을 적용

// 버튼을 클릭할 때마다 DOM을 직접 업데이트
document.getElementById('myButton').addEventListener('click', () => {
element.style.color = 'red'; // 색상 변경
element.innerHTML = 'Button clicked!'; // 내용 변경
});

### Virtual DOM 조작

<!-- <!-- // Virtual DOM을 사용하는 React 예시
import React, { useState } from 'react';

function MyComponent() {
  const [text, setText] = useState('Hello, world!'); // 상태 관리

  const handleClick = () => {
    setText('Button clicked!');  // 상태가 변경되면 React가 자동으로 Virtual DOM에서 비교 후 업데이트
  };

  return (
    <div id="myElement" style={{ color: 'black' }}>
      {text}
      <button id="myButton" onClick={handleClick}>Click me</button>
    </div>
  ); -->

export default MyComponent;

### JSX?

html태그 처럼 생겼지만 자바스크립트의 확장 문법이라 생각하면 쉽다.

### 이런식으로 실제 DOM으로 render함

<img width="369" alt="스크린샷 2024-09-30 오전 11 27 48" src="https://github.com/user-attachments/assets/98cb020e-e571-49af-b1c1-c61baca92566">

<img width="420" alt="스크린샷 2024-09-30 오전 11 28 00" src="https://github.com/user-attachments/assets/f3549067-20d6-41c6-853a-f90bb497cd1d">

# DIFFING 알고리즘 ( 구별하다)

위에서 했던 기능을 알고리즘화 한것 (리액트)

virtual DOM이 업데이트되면, React는 무엇이 바뀌었는지 업데이트 이전과 이후에 스냅샷을 비교하여 어떤것이 바뀌었는가 검사하는것.

좀더 설명하면 아래의 부연 이미지.

<img width="364" alt="스크린샷 2024-09-30 오전 11 28 09" src="https://github.com/user-attachments/assets/1c71953c-4a76-4e0f-b28f-9178ee1d743a">

쩄든 비교해서 뭐가 바뀌었나를 파악하는것

# 실제 예시

<img width="420" alt="스크린샷 2024-09-30 오전 11 28 20" src="https://github.com/user-attachments/assets/4d855add-99a4-4fdc-b526-614e8db390d0">

클릭하면 이미지가 늘어나는 앱이라 생각

<img width="422" alt="스크린샷 2024-09-30 오전 11 28 32" src="https://github.com/user-attachments/assets/f1392280-0571-449f-85dc-cea080d5c7c1">

이미지가 추가가 되었으니 자바스크립트 코드의 변경이 일어남

그럼 이전 시점과 비교를 함

<img width="426" alt="스크린샷 2024-09-30 오전 11 28 41" src="https://github.com/user-attachments/assets/39a8f0c5-f57b-4284-b97f-a455700a11e2">

# 그럼 무조건 virtual DOM을 써야하는가?

그렇지는 않다.

인터렉션이 발생하지 않는 ( 단순 정보 단방향) 사이트일경우
그냥 DOM이 더 적절하다.

또한 diffing algorithm의 시간 또한 고려해야함

spa로 제작된 큰 규모에서는 virtual DOM이 좀 더 적절하다 (일반적으로)

# Application

사용자가 특정 작업을 수행할 수 있도록 설계된 소프트웨어 프로그램

헷갈린다면 운영체제의 자원을 써서 동작하는 놈

그래도 헷갈린다면 롤, 워드, 등등등 이 애플리케이션이라고 한다.

• **애플리케이션**은 사용자가 특정 작업을 수행하는 데 중점을 둔 소프트웨어입니다.

• **프로그램**은 좀 더 포괄적인 용어로, 애플리케이션도 프로그램의 일종입니다. 프로그램은 특정 작업을 수행하는 일련의 명령어를 뜻합니다.

• **시스템 소프트웨어**는 운영체제나 드라이버처럼 하드웨어와 소프트웨어의 상호작용을 관리하는 소프트웨어입니다. 시스템 소프트웨어는 애플리케이션이 하드웨어 자원을 효율적으로 사용할 수 있도록 지원합니다.

# 먼저, SPA 과 MPA의 차이점

오늘날 웹 애플리케이션을 개발한다고 하면 대부분 React, Angular, Vue와 같은 자바스크립트 기반 프레임워크를 사용해 SPA를 개발한다.

# SPA(Single-page- Application)

하나의 페이지로 구성된 웹 애플리케이션이다. SPA로 개발된 웹사이트에서는 카테고리에 있는 각 메뉴를 선택하면 보통 헤더는 고정되어 있는 상태로 메인화면 혹은 클릭한 부분만 바뀐다.  
키포인트는 클릭한 부분만 ! 바뀐다는 것이다.

# MPA (Multi-page-Application)

반면 MPA란, Multi Page Application의 약자로, 탭을 이동할 때마다 서버로부터 새로운 HTML을 새로 받아와서 페이지 전체를 렌더링 하는 전통적인 웹 페이지 구성 방식이다

- 랜더링의 방식의 차이로 둘을 구별한다.

## SSR( SERVER SIDE RENDERING)

SSR라고도 불리는 서버사이드 렌더링은 mpa에서 쓰인다.
서버로부터 완전하게 만들어진 HTML파일로 전체로 렌더링

순서대로 작성하면

1. 유저가 웹사이트에 방문하면, 브라우저가 서버에 콘텐츠를 요청한다.
2. 이에 서버는 페이지에 필요한 데이터를 즉시 얻어와 모두 삽입하고, CSS까지 모두 적용해 렌더링 준비를 마친 HTML과 JavaScript코드를 브라우저에 응답으로 전달한다.
3. 브라우저에서는 JavaScript코드를 다운로드하고 HTML에 JavaScript로직을 연결한다.

중요하게 볼 관점은 2번이다. 2. 모든 데이터가 이미 완전한 상태의 HTML에 담긴채로 브라우저에 전달이 되기 때문에, 무리 없이 읽는것이 가능하다. (즉 완전한 상태의 HTML이 JS 코드 전에 완성되기에
사용자 입장에서는 로딩속도가 비교적 빠르게 보이겠다.)

하지만 무건적으로 빠르다고 좋은 것은 아닌것이, Js 코드의 로직이 연결되기 전에 사용자가 클릭을 한다면, 동적 이벤트가 적용이 안될 가능성도 있다.

이것간의 시간간격 (엄밀히 말하면 TTV(Time to View)와 TTI(Time to Interact) 간의 시간 간격)은 서버 사이드 렌더링 방식에 단점이라고 볼 수 있다.

반면 아래에 기술할 CSR은 이 TIME INTERVAL이 없다. 같은 시점에 완성되기 때문에.

아래는 간략한 사진을 넣어서 설명한다.

<img width="417" alt="스크린샷 2024-09-30 오전 11 28 50" src="https://github.com/user-attachments/assets/c59caf0f-a8d3-44c2-a0ee-085a373ffd38">

1. 나무를 옮겨본다고 예시를 들었을때.

<img width="418" alt="스크린샷 2024-09-30 오전 11 28 58" src="https://github.com/user-attachments/assets/b6707fb8-fbb7-48bf-be0f-6f509e321a7f">

<img width="418" alt="스크린샷 2024-09-30 오전 11 29 07" src="https://github.com/user-attachments/assets/1cbc58a9-2e78-476c-9d71-b8b3213dae24">

응답할때는 html 파일로 줌 (서버가)

<img width="420" alt="스크린샷 2024-09-30 오전 11 29 37" src="https://github.com/user-attachments/assets/cc92609b-513a-46bb-ac38-14cf4d7e1e15">

받은걸 모조리 서버부터 다시 다운

<img width="393" alt="스크린샷 2024-09-30 오전 11 29 46" src="https://github.com/user-attachments/assets/c35fa9bc-ae45-4e59-b734-995af48d3109">

그래서 화면이 깜빡이고 앱이 재시작된다.

### 장점

검색 엔진 최적화에 유리

검색엔진이 웹을 크롤링하면서 페이지에 컨텐츠 색인을 생성하는 과정

화면 구성 웹페이지가 각각 있어서 이점에서 유리

- 빠른 초기 로딩 속도

### 단점

사용자 경험이 좋지 않다. + 서버 부하

### 크롤링(참고자료)

**크롤링의 동작 방식**

1. **시작점 설정 (Seed URL)**: 크롤러는 웹사이트의 특정 URL(예: 홈 페이지)에서 시작합니다.

2. **페이지 다운로드**: 크롤러는 해당 페이지의 HTML 문서를 다운로드하고, 페이지에 포함된 텍스트, 이미지, 링크 등의 데이터를 수집합니다.

3. **링크 추출 및 탐색**: 크롤러는 웹 페이지 안의 링크들을 분석하여 새로운 페이지를 찾습니다. 이렇게 찾은 링크들은 큐에 추가되고, 크롤러는 이들을 순차적으로 방문하여 데이터를 계속 수집합니다.

4. **데이터 저장**: 수집된 데이터는 로컬 파일이나 데이터베이스에 저장되며, 이후 분석하거나 처리할 수 있습니다.
   ;;;
   **크롤링의 용도**

5. **검색 엔진**: 구글이나 네이버 같은 검색 엔진은 웹 크롤러를 사용하여 수많은 웹 페이지를 탐색하고 인덱스를 생성하여, 사용자가 검색할 때 적절한 페이지를 빠르게 찾을 수 있게 합니다.

6. **데이터 수집 및 분석**: 특정 웹사이트에서 상품 정보, 리뷰, 기사 등을 대량으로 수집하여 분석하는 데 사용됩니다.

7. **가격 비교 사이트**: 여러 쇼핑몰의 가격을 비교하는 사이트는 크롤링을 통해 실시간으로 상품 정보를 수집합니다.

8. **뉴스 수집**: 뉴스 웹사이트에서 새로운 기사를 자동으로 수집하여 보여주는 뉴스 집계 사이트들도 크롤링을 이용합니다.

**크롤링의 장단점**

**장점:**

• **자동화**: 크롤러는 수많은 웹 페이지를 사람이 일일이 탐색하지 않아도 자동으로 수집할 수 있습니다.

• **빠른 데이터 수집**: 대량의 데이터를 빠르게 수집할 수 있어 시간과 노력을 절약합니다.

**단점:**

• **차단 가능성**: 웹사이트에 따라 크롤링을 막기 위해 robots.txt 파일을 통해 크롤러의 접근을 제한하거나, 너무 많은 요청을 보내는 경우 서버에서 차단할 수 있습니다.

# CSR (Client Side Rendering)

Single Page App에서 주로 이 방식으로 렌더링을 한다.

개인적인 생각으로 CSR의 가장 중요한 키워드는 빈 뼈대만 있는 HTML을 준다는 것이다

SPA는 웹 애플리케이션에 필요한 정적 리소스를 한꺼번에 모두 다운로드하고, 이후 새로운 페이지 요청이 왔을 때 필요한 데이터만 전달받아서 클라이언트에서 필요한 페이지를 갱신하기 때문에 CSR로 렌더링 한다.

한꺼번에 모두 다운로드를 하기에 모든 js파일까지 다 받아야해서 초기 로딩속도가 느림
Clinet Side Rendering 이라는 용어 그대로
클라이언트 측에서 렌더링을 하는 방식이다.

위의 예시에서 웹페이지의 나무라는 요소를 바꾸려고 서버에 요구를 한다면
client server rendering(csr)은 그냥 나무라는 요소의 데이터만 가져다주어
그 요소만 변화를 취한다.

아래의 간략한 순서이다.

즉, 여기서는 브라우저의 역할이 서버의 역할(빈껍데기 제공) 보다 훨씬 중하기에
클라이언트 렌더링 방식 이라고 이해해도 괜찮다.

1. 유저가 웹사이트에 방문하면, 브라우저가 서버에 콘텐츠를 요청한다.
2. 이에 서버는 빈 뼈대만 있는 HTML을 응답으로 보내준다.
3. 브라우저가 연결된 JavaScript 링크를 통해 서버로부터 다시 JavaScript 파일을 다운로드한다.

4. JavaScript를 통해 동적으로 페이지를 만들어 브라우저에 띄워준다.

여기서 4번을 주목하면 좋은데, CSR은 브라우저가 JavaScript 파일을 다운로드하고, 동적으로 DOM을 생성하는 시간을 기다려야 하기 때문에 초기 로딩 속도가 느리다는 것이 단점이다.

하지만 초기 로딩 이후에 페이지 일부를 변경할 때는 서버에서 해당 데이터만 요청하면 되기 때문에 이후 구동 속도는 빠르다는 특징이 있다.

또한 동작 시점과 html 완성 시점이 같은 것도 장점.

### 서버의 부하가 CSR에서 좋은 이유?

서버는 빈 뼈대만 있는 HTML을 넘겨주는 역할만 수행하면 되기 때문에 서버 측의 부하가 적은데, 뿐만 아니라 클라이언트 측에서 연산, 라우팅 등을 모두 직접 처리하기 때문에 반응속도가 빠르고 UX도 우수하다는 장점이 있다.

# 장점

- 속도가 매우 빠르며 서버 부하가 없음
- 사용자입장에선 친화적인 경향 (반짝이지는 않으니)
- 부드러운 이동

# 단점

- 검색엔진 최적화에 불리
- 크롤러가 오작동 할 가능성이 있다.
- 초기 로딩속도가 김(자바스크립트 코드 전체를 통으로 가져오므로 서버에서)

# 질문

## SPA는 ssr못하고 csr만 하나요?

즉 single page app은 오직 client server rendering의 방식만 고수하냐는 질문이다.

이분법적으로 생각하면 좋지않다.

모든것이 다 이분법적으로 나눠지는 시스템이 아님
xq

# 결론

컨텐츠를 개발의 방향을 정해야한다.

모든 부분을 csr 혹은 ssr로 개발을 하는 건 현명한 선택이 아님.
만약 정보제공만을 위한 단방향성 개발이 필요하면
ssr (server side rendering)

즉 서버와 접촉이 많이 없는 컨텐츠이면 이게 맞고
만약 동적인 움직임이 많거나 사용자와의 접촉이 많아 서버와의 접촉이 많아지면
csr (client side Rendering)으로 하는게 좀 더 적절하다고 판단 내려질수있다.

# 방향성

서버의 부하가 많아질수밖에 없으면 CSR

서버의 부하가 많아질일이 거의 없다면
SSR 방식을 고수하면 될 것같다.
✔️ CSR

- 유저와 상호작용이 많다

- 대부분이 고객의 개인정보로 이루어진 페이지들이라 검색엔진에 노출될 필요는 없다

✔️ SSR

- 회사 홈페이지여서 홍보나 상위노출이 필요하다

- 누구에게나 항상 같은 내용을 보여준다

- 업데이트가 빈번해 해당 페이지 데이터가 자주 바뀐다

# 그럼 왜 MPA 에서는 SSR, SPA에서는 CSR의 방식을 쓰나?

한 페이지에서 무쌍을 찍는 뭐 인스타그램 포스트 이런곳은 서버의 부하가 많아지기니까 csr + spa 의 방식으로 서버 부하를 줄이고,
쇼핑몰, 블로그 같이 사람이 직접 어디에 들어가 새로고침이 불가피한곳은 서버의 부하가 비교적 적으니 (변화무쌍이 적으니) ssr 방식으로 해도 좋다.

즉 최종 결론은 서버의 부하가 어느정도이냐에 따라서
유연하게 쓰면 될 것

## 참고자료

https://dev-ellachoi.tistory.com/28

- Youtube 우아한테크: [10분 테코톡] 🎨 신세한탄
  https://velog.io/@ye-ji/DOM-vs-Virtual-DOM의 CSR&SSR
